{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Search: Playing \"Mean\" Connect 4\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: Undegraduates 10, graduate students 11\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with your implementation, documentation including a short discussion of how your implementation works and your design choices, and experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "You will implement different versions of agents that play \"Mean\" Connect 4:\n",
    "\n",
    "> \"Connect 4 is a two-player connection board game, in which the players choose a color and then take turns dropping colored discs into a seven-column, six-row vertically suspended grid. The pieces fall straight down, occupying the lowest available space within the column. The objective of the game is to be the first to form a horizontal, vertical, or diagonal line of four of one's own discs.\" (see [Connect Four on Wikipedia](https://en.wikipedia.org/wiki/Connect_Four))\n",
    "\n",
    "> **The mean part:** This game has an additional rule. Every time it is a player's turn, the player can decide to instead of playing a new disk, take a bottom row disk of the opponent and place it in any column. All disks above the removed disk will fall down one position. Note that a player can only move an _opponent's disc_ that is in the _bottom row_ of the board.\n",
    "\n",
    "Note that normal [Connect-4 has been solved](https://en.wikipedia.org/wiki/Connect_Four#Mathematical_solution)\n",
    "in 1988. A connect-4 solver with a discussion of how to solve different parts of the problem can be found here: https://connect4.gamesolver.org/en/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Defining the Search Problem [1 point]\n",
    "\n",
    "Define the components of the search problem associated with this game:\n",
    "\n",
    "* Initial state\n",
    "* Actions\n",
    "* Transition model\n",
    "* Test for the terminal state\n",
    "* Utility for terminal states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/answer goes here.\n",
    "# ...existing code...\n",
    "import numpy as np\n",
    "\n",
    "def actions(board, player):\n",
    "    \"\"\"Trả về list các hành động hợp lệ trên board cho player.\n",
    "    Hành động: (\"drop\", col) hoặc (\"steal\", from_col, to_col).\n",
    "    board: numpy array shape (rows, cols), values in {0,1,-1}.\n",
    "    \"\"\"\n",
    "    rows, cols = board.shape\n",
    "    acts = []\n",
    "    # drop actions: cột không đầy\n",
    "    for c in range(cols):\n",
    "        if board[0, c] == 0:\n",
    "            acts.append((\"drop\", c))\n",
    "    # steal actions: bottom row có đĩa của opponent\n",
    "    opp = -player\n",
    "    for c_from in range(cols):\n",
    "        if board[-1, c_from] == opp:\n",
    "            # destination columns that have space\n",
    "            for c_to in range(cols):\n",
    "                if board[0, c_to] == 0:\n",
    "                    acts.append((\"steal\", c_from, c_to))\n",
    "    return acts\n",
    "\n",
    "def result(board, action, player):\n",
    "    \"\"\"Áp dụng action lên board và trả về board mới (không thay đổi board gốc).\"\"\"\n",
    "    b = board.copy()\n",
    "    rows, cols = b.shape\n",
    "    if action[0] == \"drop\":\n",
    "        _, c = action\n",
    "        if b[0, c] != 0:\n",
    "            raise Exception(f\"Illegal drop: column {c} is full\")\n",
    "        for r in range(rows-1, -1, -1):\n",
    "            if b[r, c] == 0:\n",
    "                b[r, c] = player\n",
    "                break\n",
    "    elif action[0] == \"steal\":\n",
    "        _, c_from, c_to = action\n",
    "        opp = -player\n",
    "        if b[-1, c_from] != opp:\n",
    "            raise Exception(f\"Illegal steal: bottom of column {c_from} is not opponent's disk\")\n",
    "        if b[0, c_to] != 0:\n",
    "            raise Exception(f\"Illegal steal: destination column {c_to} is full\")\n",
    "        # remove bottom disk at c_from and shift column down\n",
    "        for r in range(rows-1, 0, -1):\n",
    "            b[r, c_from] = b[r-1, c_from]\n",
    "        b[0, c_from] = 0\n",
    "        # place the stolen disk (its value remains opponent's)\n",
    "        for r in range(rows-1, -1, -1):\n",
    "            if b[r, c_to] == 0:\n",
    "                b[r, c_to] = opp\n",
    "                break\n",
    "    else:\n",
    "        raise Exception(f\"Unknown action type: {action[0]}\")\n",
    "    return b\n",
    "\n",
    "def check_four_in_a_row(board, connect=4):\n",
    "    \"\"\"Kiểm tra người thắng: trả về 1 nếu player 1 thắng, -1 nếu player -1 thắng, 0 nếu chưa có.\"\"\"\n",
    "    rows, cols = board.shape\n",
    "    directions = [(0,1), (1,0), (1,1), (1,-1)]  # horiz, vert, diag down-right, diag down-left\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            val = board[r, c]\n",
    "            if val == 0:\n",
    "                continue\n",
    "            for dr, dc in directions:\n",
    "                cnt = 1\n",
    "                rr, cc = r, c\n",
    "                for _ in range(1, connect):\n",
    "                    rr += dr; cc += dc\n",
    "                    if 0 <= rr < rows and 0 <= cc < cols and board[rr, cc] == val:\n",
    "                        cnt += 1\n",
    "                    else:\n",
    "                        break\n",
    "                if cnt >= connect:\n",
    "                    return int(val)\n",
    "    return 0\n",
    "\n",
    "def terminal(board, connect=4):\n",
    "    \"\"\"Trả về (is_terminal, winner). winner: 1, -1 cho thắng, 0 cho hòa, None nếu chưa kết thúc.\"\"\"\n",
    "    winner = check_four_in_a_row(board, connect=connect)\n",
    "    if winner != 0:\n",
    "        return True, winner\n",
    "    if not (board == 0).any():\n",
    "        return True, 0\n",
    "    return False, None\n",
    "\n",
    "def utility(board, player, connect=4):\n",
    "    \"\"\"Utility cho player: +1 thắng, -1 thua, 0 hòa. None nếu chưa terminal.\"\"\"\n",
    "    is_term, winner = terminal(board, connect=connect)\n",
    "    if not is_term:\n",
    "        return None\n",
    "    if winner == 0:\n",
    "        return 0\n",
    "    return 1 if winner == player else -1\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the state space? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board 6x7\n",
      "Số cấu hình thô (mỗi ô 3 trạng thái): 3^(rows*cols) = 109418989131512359209\n",
      "≈ 1.094e+20\n",
      "log10(3^(rows*cols)) = 20.039\n",
      "\n",
      "Giải thích: mỗi ô có 3 trạng thái (empty/1/-1) ⇒ thô = 3^(rows*cols).\n",
      "Số trạng thái hợp lệ (theo quy tắc rơi) nhỏ hơn nhưng cùng bậc lớn — quá lớn để duyệt toàn bộ.\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "import math\n",
    "\n",
    "# Task1 - Cell 1: Ước lượng kích thước không gian trạng thái\n",
    "rows, cols = 6, 7  # mặc định board chuẩn\n",
    "states_tho = 3 ** (rows * cols)\n",
    "print(f\"Board {rows}x{cols}\")\n",
    "print(\"Số cấu hình thô (mỗi ô 3 trạng thái): 3^(rows*cols) =\", states_tho)\n",
    "print(\"≈ {:.3e}\".format(states_tho))\n",
    "print(\"log10(3^(rows*cols)) = {:.3f}\".format(math.log10(states_tho)))\n",
    "\n",
    "# Giải thích ngắn:\n",
    "print(\"\\nGiải thích: mỗi ô có 3 trạng thái (empty/1/-1) ⇒ thô = 3^(rows*cols).\")\n",
    "print(\"Số trạng thái hợp lệ (theo quy tắc rơi) nhỏ hơn nhưng cùng bậc lớn — quá lớn để duyệt toàn bộ.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How big is the game tree that minimax search will go through? Give an estimate and explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Độ sâu tối đa d ≤ rows*cols = 42\n",
      "Ước lượng branching factor b ≈ 7 — 14 (ví dụ dùng b = 10)\n",
      "Ví dụ nếu b = 10 thì số nút ≈ b^d và log10(nodes) = 42.0\n",
      "⇒ nodes ≈ 10^42.0 (rất lớn, không khả thi để duyệt toàn bộ)\n",
      "\n",
      "Kết luận ngắn: cần dùng alpha-beta, cắt tỉa theo độ sâu, heuristic hoặc board nhỏ hơn để tìm lời giải khả thi.\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "import math\n",
    "\n",
    "# Task1 - Cell 2: Ước lượng kích thước cây trò chơi (minimax)\n",
    "rows, cols = 6, 7\n",
    "d_max = rows * cols\n",
    "\n",
    "# branching factor ước lượng: tối thiểu ~ số cột (drop only), tối đa thêm tùy chọn steal (~+cols)\n",
    "b_min = cols\n",
    "b_max = cols * 2\n",
    "b_example = 10  # ví dụ minh họa trung bình\n",
    "\n",
    "print(f\"Độ sâu tối đa d ≤ rows*cols = {d_max}\")\n",
    "print(f\"Ước lượng branching factor b ≈ {b_min} — {b_max} (ví dụ dùng b = {b_example})\")\n",
    "\n",
    "# ước lượng log10 số nút để dễ hình dung\n",
    "log10_nodes_example = d_max * math.log10(b_example)\n",
    "print(\"Ví dụ nếu b = {} thì số nút ≈ b^d và log10(nodes) = {:.1f}\".format(b_example, log10_nodes_example))\n",
    "print(\"⇒ nodes ≈ 10^{:.1f} (rất lớn, không khả thi để duyệt toàn bộ)\".format(log10_nodes_example))\n",
    "\n",
    "print(\"\\nKết luận ngắn: cần dùng alpha-beta, cắt tỉa theo độ sâu, heuristic hoặc board nhỏ hơn để tìm lời giải khả thi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Game Environment and Random Agent [3 point]\n",
    "\n",
    "You can use a numpy character array as the board. Note that the following function can create boards of different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def empty_board(shape=(6, 7)):\n",
    "    return np.full(shape=shape, fill_value=0)\n",
    "\n",
    "print(empty_board())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of colors (red and yellow), you can use 1 and -1 to represent the players Max and Min. Make sure that your agent functions all have the from: `agent_type(board, player = 1)`, where board is the current board position and player is the player (1, -1) whose next move it is and who the agent should play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization code by Randolph Rankin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize(board):\n",
    "    plt.axes()\n",
    "    rectangle=plt.Rectangle((-0.5,len(board)*-1+0.5),len(board[0]),len(board),fc='blue')\n",
    "    circles=[]\n",
    "    for i,row in enumerate(board):\n",
    "        for j,val in enumerate(row):\n",
    "            color='white' if val==0 else 'red' if val==1 else 'yellow'\n",
    "            circles.append(plt.Circle((j,i*-1),0.4,fc=color))\n",
    "\n",
    "    plt.gca().add_patch(rectangle)\n",
    "    for circle in circles:\n",
    "        plt.gca().add_patch(circle)\n",
    "\n",
    "    plt.axis('scaled')\n",
    "    plt.show()\n",
    "    \n",
    "board = [[0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 0, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 0, 0, 0],\n",
    "         [0, 0, 0, 1, 0, 0, 0],\n",
    "         [0,-1,-1, 1,-1, 0, 0]]\n",
    "\n",
    "visualize(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement helper functions for:\n",
    "\n",
    "* The transition model $result(s, a)$.\n",
    "* The utility function $utility(s)$.\n",
    "* Check for terminal states $terminal(s)$.\n",
    "* A check for available actions in each state $actions(s)$.\n",
    "\n",
    "Make sure that all these functions work with boards of different sizes (number of columns and rows)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "import numpy as np\n",
    "\n",
    "def empty_board(shape=(6,7)):\n",
    "    return np.full(shape=shape, fill_value=0)\n",
    "\n",
    "def actions(board, player):\n",
    "    \"\"\"Trả về list các hành động hợp lệ: (\"drop\", col) hoặc (\"steal\", from_col, to_col).\"\"\"\n",
    "    rows, cols = board.shape\n",
    "    acts = []\n",
    "    for c in range(cols):\n",
    "        if board[0, c] == 0:\n",
    "            acts.append((\"drop\", c))\n",
    "    opp = -player\n",
    "    for c_from in range(cols):\n",
    "        if board[-1, c_from] == opp:\n",
    "            for c_to in range(cols):\n",
    "                if board[0, c_to] == 0:\n",
    "                    acts.append((\"steal\", c_from, c_to))\n",
    "    return acts\n",
    "\n",
    "def result(board, action, player):\n",
    "    \"\"\"Áp dụng action và trả board mới (không thay đổi board gốc).\"\"\"\n",
    "    b = board.copy()\n",
    "    rows, cols = b.shape\n",
    "    if action[0] == \"drop\":\n",
    "        _, c = action\n",
    "        if b[0, c] != 0:\n",
    "            raise Exception(f\"Illegal drop: column {c} is full\")\n",
    "        for r in range(rows-1, -1, -1):\n",
    "            if b[r, c] == 0:\n",
    "                b[r, c] = player\n",
    "                break\n",
    "    elif action[0] == \"steal\":\n",
    "        _, c_from, c_to = action\n",
    "        opp = -player\n",
    "        if b[-1, c_from] != opp:\n",
    "            raise Exception(\"Illegal steal: bottom not opponent\")\n",
    "        if b[0, c_to] != 0:\n",
    "            raise Exception(\"Illegal steal: destination full\")\n",
    "        for r in range(rows-1, 0, -1):\n",
    "            b[r, c_from] = b[r-1, c_from]\n",
    "        b[0, c_from] = 0\n",
    "        for r in range(rows-1, -1, -1):\n",
    "            if b[r, c_to] == 0:\n",
    "                b[r, c_to] = opp\n",
    "                break\n",
    "    else:\n",
    "        raise Exception(\"Unknown action\")\n",
    "    return b\n",
    "\n",
    "def check_four_in_a_row(board, connect=4):\n",
    "    rows, cols = board.shape\n",
    "    dirs = [(0,1),(1,0),(1,1),(1,-1)]\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            v = board[r,c]\n",
    "            if v == 0: continue\n",
    "            for dr,dc in dirs:\n",
    "                cnt = 1\n",
    "                rr,cc = r,c\n",
    "                for _ in range(1,connect):\n",
    "                    rr += dr; cc += dc\n",
    "                    if 0 <= rr < rows and 0 <= cc < cols and board[rr,cc] == v:\n",
    "                        cnt += 1\n",
    "                    else:\n",
    "                        break\n",
    "                if cnt >= connect:\n",
    "                    return int(v)\n",
    "    return 0\n",
    "\n",
    "def terminal(board, connect=4):\n",
    "    winner = check_four_in_a_row(board, connect)\n",
    "    if winner != 0:\n",
    "        return True, winner\n",
    "    if not (board == 0).any():\n",
    "        return True, 0\n",
    "    return False, None\n",
    "\n",
    "def utility(board, player, connect=4):\n",
    "    is_term, winner = terminal(board, connect)\n",
    "    if not is_term:\n",
    "        return None\n",
    "    if winner == 0:\n",
    "        return 0\n",
    "    return 1 if winner == player else -1\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement an agent that plays randomly. Make sure the agent function receives as the percept the board and returns a valid action. Use an agent function definition with the following signature (arguments):\n",
    "\n",
    "`def random_player(board, player = None): ...`\n",
    "\n",
    "The argument `player` is used for agents that do not store what side they are playing. The value passed on bt yhe environment should be 1 ot -1 for playerred and yellow, respectively.  See [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "import numpy as np\n",
    "\n",
    "def random_player(board, player = None):\n",
    "    \"\"\"Agent ngẫu nhiên chọn action hợp lệ.\"\"\"\n",
    "    if player is None:\n",
    "        player = 1\n",
    "    acts = actions(board, player)\n",
    "    if not acts:\n",
    "        return None\n",
    "    return acts[np.random.randint(len(acts))]\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let two random agents play against each other 1000 times. Look at the [Experiments section for tic-tac-toe](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_and_or_tree_search.ipynb#Experiments) to see how the environment uses the agent functions to play against each other.\n",
    "\n",
    "How often does each player win? Is the result expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played 100/1000\n",
      "Played 200/1000\n",
      "Played 300/1000\n",
      "Played 400/1000\n",
      "Played 500/1000\n",
      "Played 600/1000\n",
      "Played 700/1000\n",
      "Played 800/1000\n",
      "Played 900/1000\n",
      "Played 1000/1000\n",
      "Kết quả: {1: 757, -1: 243, 0: 0}\n",
      "P1: 757 (75.70%), P-1: 243 (24.30%), Draw: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "import time\n",
    "\n",
    "def play(x_agent, o_agent, N = 100, show_final_board = False, verbose = False):\n",
    "    results = {1:0, -1:0, 0:0}\n",
    "    for i in range(N):\n",
    "        board = empty_board()\n",
    "        player = 1\n",
    "        while True:\n",
    "            agent = x_agent if player == 1 else o_agent\n",
    "            action = agent(board.copy(), player)\n",
    "            if action is None:\n",
    "                # no legal moves -> draw\n",
    "                results[0] += 1\n",
    "                break\n",
    "            if action not in actions(board, player):\n",
    "                raise Exception(f\"Illegal action {action} by player {player}\")\n",
    "            board = result(board, action, player)\n",
    "            is_term, winner = terminal(board)\n",
    "            if is_term:\n",
    "                results[winner] += 1\n",
    "                break\n",
    "            player = -player\n",
    "        if verbose and (i+1) % 100 == 0:\n",
    "            print(f\"Played {i+1}/{N}\")\n",
    "    return results\n",
    "\n",
    "# Ví dụ chạy 1000 trận giữa hai random agents\n",
    "res = play(random_player, random_player, N=1000, verbose=True)\n",
    "total = sum(res.values())\n",
    "print(\"Kết quả:\", res)\n",
    "print(f\"P1: {res[1]} ({res[1]/total:.2%}), P-1: {res[-1]} ({res[-1]/total:.2%}), Draw: {res[0]} ({res[0]/total:.2%})\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Minimax Search with Alpha-Beta Pruning [3 points]\n",
    "\n",
    "### Implement the search starting.\n",
    "\n",
    "Implement the search starting from a given board and specifying the player and put it into an agent function.\n",
    "You can use code from the [tic-tac-toe example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_alpha_beta_tree_search.ipynb).\n",
    "\n",
    "__Notes:__ \n",
    "* Make sure that all your agent functions have a signature consistent with the random agent above.\n",
    "* The search space for a $6 \\times 7$ board is large. You can experiment with smaller boards (the smallest is $4 \\times 4$) and/or changing the winning rule to connect 3 instead of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Minimax with Alpha-Beta\n",
    "# =========================\n",
    "# Giải thích (tiếng Việt):\n",
    "# - alphabeta: triển khai minimax với alpha-beta pruning, hỗ trợ độ sâu cắt (max_depth)\n",
    "#   và heuristic (khi depth == 0).\n",
    "# - minimax_agent: agent dùng alphabeta để chọn hành động; mặc định dùng MAX_DEPTH.\n",
    "#   Signature agent(board, player=1) để tương thích với môi trường.\n",
    "\n",
    "MINIMAX_MAX_DEPTH = 4   # chỉnh nếu muốn sâu hơn (chú ý thời gian)\n",
    "CONNECT = 4              # số quân liên tiếp cần thắng\n",
    "\n",
    "def basic_heuristic(board, player, connect=CONNECT):\n",
    "    # Heuristic đơn giản: đếm các chuỗi 2 hoặc 3 chưa bị chặn cho player minus opponent\n",
    "    rows, cols = board.shape\n",
    "    dirs = [(0,1),(1,0),(1,1),(1,-1)]\n",
    "    def score_for(p):\n",
    "        score = 0\n",
    "        for r in range(rows):\n",
    "            for c in range(cols):\n",
    "                if board[r,c] == 0:\n",
    "                    continue\n",
    "                # only start from p's cells\n",
    "                if board[r,c] != p:\n",
    "                    continue\n",
    "                for dr,dc in dirs:\n",
    "                    cnt = 1\n",
    "                    rr,cc = r,c\n",
    "                    blocked = False\n",
    "                    for _ in range(1, connect):\n",
    "                        rr += dr; cc += dc\n",
    "                        if 0 <= rr < rows and 0 <= cc < cols:\n",
    "                            if board[rr,cc] == p:\n",
    "                                cnt += 1\n",
    "                            elif board[rr,cc] == 0:\n",
    "                                # potential extension\n",
    "                                pass\n",
    "                            else:\n",
    "                                blocked = True\n",
    "                                break\n",
    "                        else:\n",
    "                            blocked = True\n",
    "                            break\n",
    "                    if not blocked:\n",
    "                        if cnt == 2:\n",
    "                            score += 1\n",
    "                        elif cnt == 3:\n",
    "                            score += 5\n",
    "        return score\n",
    "\n",
    "    return score_for(player) - score_for(-player)\n",
    "\n",
    "def _is_terminal_value(board, root_player):\n",
    "    # dùng utility đã có: trả về +1/-1/0 cho terminal, None nếu chưa terminal\n",
    "    u = utility(board, root_player, connect=CONNECT)\n",
    "    if u is None:\n",
    "        return None\n",
    "    # scale so wins are large magnitudes for alpha-beta to prefer them\n",
    "    return int(u * 1000)\n",
    "\n",
    "def alphabeta(board, depth, alpha, beta, player, root_player, max_depth=MINIMAX_MAX_DEPTH, heuristic_fn=None):\n",
    "    # returns (value, best_action)\n",
    "    term = _is_terminal_value(board, root_player)\n",
    "    if term is not None:\n",
    "        return term, None\n",
    "    if depth == 0:\n",
    "        if heuristic_fn is not None:\n",
    "            return heuristic_fn(board, root_player, connect=CONNECT), None\n",
    "        return 0, None\n",
    "\n",
    "    best_action = None\n",
    "    value = -1e9\n",
    "    acts = actions(board, player)\n",
    "    if not acts:\n",
    "        return 0, None\n",
    "\n",
    "    # iterate actions (can add ordering here later)\n",
    "    for a in acts:\n",
    "        child = result(board, a, player)\n",
    "        v_child, _ = alphabeta(child, depth-1, -beta, -alpha, -player, root_player, max_depth, heuristic_fn)\n",
    "        v = -v_child\n",
    "        if v > value:\n",
    "            value = v; best_action = a\n",
    "        if value > alpha:\n",
    "            alpha = value\n",
    "        if alpha >= beta:\n",
    "            break\n",
    "    return value, best_action\n",
    "\n",
    "def minimax_agent(board, player = 1):\n",
    "    \"\"\"Agent dùng alphabeta. Trả về hành động hợp lệ.\"\"\"\n",
    "    # nếu board hoàn toàn rỗng -> heuristic opening: chọn cột giữa\n",
    "    if (board == 0).all():\n",
    "        cols = board.shape[1]\n",
    "        mid = cols // 2\n",
    "        if board[0, mid] == 0:\n",
    "            return (\"drop\", mid)\n",
    "    _, act = alphabeta(board, MINIMAX_MAX_DEPTH, -1e9, 1e9, player, player, max_depth=MINIMAX_MAX_DEPTH, heuristic_fn=basic_heuristic)\n",
    "    return act\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with some manually created boards (at least 5) to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: Horizontal immediate win\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [1 1 1 0 0 0 0]]\n",
      "Agent chọn: ('drop', 0)\n",
      "----------------------------------------\n",
      "Test: Vertical immediate win\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0]\n",
      " [0 0 0 0 1 0 0]]\n",
      "Agent chọn: ('drop', 0)\n",
      "----------------------------------------\n",
      "Test: Diagonal immediate win\n",
      "[[0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0]]\n",
      "Agent chọn: ('drop', 0)\n",
      "----------------------------------------\n",
      "Test: Block opponent horizontal\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [-1 -1 -1  0  0  0  0]]\n",
      "Agent chọn: ('steal', 0, 5)\n",
      "----------------------------------------\n",
      "Test: Steal scenario\n",
      "[[ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0]\n",
      " [-1  1  0  0  0  0  0]]\n",
      "Agent chọn: ('drop', 0)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "# =========================\n",
    "# Task 3 — Kiểm tra với vài board mẫu (ít nhất 5)\n",
    "# =========================\n",
    "# Mục đích: kiểm tra agent có nhận ra nước thắng/chặn thắng tức thì.\n",
    "# Mỗi board in ra và in hành động agent chọn + giải thích ngắn.\n",
    "\n",
    "def make_board_from_moves(rows=6, cols=7, moves=[]):\n",
    "    b = empty_board((rows, cols))\n",
    "    for player, act in moves:\n",
    "        b = result(b, act, player)\n",
    "    return b\n",
    "\n",
    "tests = []\n",
    "# Test 1: horizontal immediate win for player 1\n",
    "b1 = empty_board()\n",
    "b1[5,0]=1; b1[5,1]=1; b1[5,2]=1; b1[5,3]=0\n",
    "tests.append((\"Horizontal immediate win\", b1, 1))\n",
    "\n",
    "# Test 2: vertical immediate win\n",
    "b2 = empty_board()\n",
    "b2[5,4]=1; b2[4,4]=1; b2[3,4]=1\n",
    "tests.append((\"Vertical immediate win\", b2, 1))\n",
    "\n",
    "# Test 3: diagonal immediate win (down-right)\n",
    "b3 = empty_board()\n",
    "b3[5,0]=1; b3[4,1]=1; b3[3,2]=1\n",
    "tests.append((\"Diagonal immediate win\", b3, 1))\n",
    "\n",
    "# Test 4: need to block opponent\n",
    "b4 = empty_board()\n",
    "b4[5,0]=-1; b4[5,1]=-1; b4[5,2]=-1\n",
    "tests.append((\"Block opponent horizontal\", b4, 1))\n",
    "\n",
    "# Test 5: steal useful example - opponent bottom disk can be stolen to make player win\n",
    "b5 = empty_board()\n",
    "# build a column where opponent's bottom disk exists\n",
    "b5[5,0] = -1\n",
    "b5[5,1] = 1; b5[4,1]=1; b5[3,1]=1  # player 1 has 3 vertical in column 1, wants a drop or steal to make 4\n",
    "tests.append((\"Steal scenario\", b5, 1))\n",
    "\n",
    "for name, board, player in tests:\n",
    "    print(\"Test:\", name)\n",
    "    print(board)\n",
    "    try:\n",
    "        act = minimax_agent(board.copy(), player)\n",
    "    except Exception as e:\n",
    "        act = f\"Error: {e}\"\n",
    "    print(\"Agent chọn:\", act)\n",
    "    print(\"-\"*40)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đo thời gian cho một nước đi (giây)\n",
      "Board 4x4, depth=2: time=0.0000s, action=('drop', 2)\n",
      "Board 4x4, depth=3: time=0.0000s, action=('drop', 2)\n",
      "Board 4x4, depth=4: time=0.0000s, action=('drop', 2)\n",
      "Board 5x5, depth=2: time=0.0000s, action=('drop', 2)\n",
      "Board 5x5, depth=3: time=0.0000s, action=('drop', 2)\n",
      "Board 5x5, depth=4: time=0.0000s, action=('drop', 2)\n",
      "Board 6x7, depth=2: time=0.0000s, action=('drop', 3)\n",
      "Board 6x7, depth=3: time=0.0000s, action=('drop', 3)\n",
      "Board 6x7, depth=4: time=0.0000s, action=('drop', 3)\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "# =========================\n",
    "# Task 3 — Thử nghiệm đo thời gian thực hiện 1 nước đi với nhiều kích thước và độ sâu\n",
    "# =========================\n",
    "# In tiếng Việt: đo thời gian cho một nước đi bởi minimax với các max_depth khác nhau.\n",
    "import time\n",
    "\n",
    "def time_one_move(rows, cols, depth):\n",
    "    global MINIMAX_MAX_DEPTH\n",
    "    MINIMAX_MAX_DEPTH = depth\n",
    "    board = empty_board((rows, cols))\n",
    "    # populate partly to make branching smaller (lấy vài nước ngẫu nhiên)\n",
    "    # nhưng ở đây để worst-case, giữ rỗng\n",
    "    t0 = time.time()\n",
    "    act = minimax_agent(board, 1)\n",
    "    t1 = time.time()\n",
    "    return t1 - t0, act\n",
    "\n",
    "sizes = [ (4,4), (5,5), (6,7) ]\n",
    "depths = [2,3,4]  # lưu ý 4 với kích thước 6x7 có thể mất lâu\n",
    "print(\"Đo thời gian cho một nước đi (giây)\")\n",
    "for (r,c) in sizes:\n",
    "    for d in depths:\n",
    "        dt, act = time_one_move(r,c,d)\n",
    "        print(f\"Board {r}x{c}, depth={d}: time={dt:.4f}s, action={act}\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move ordering\n",
    "\n",
    "Starting the search with better moves will increase the efficiency of alpha-beta pruning. Describe and implement a simple move ordering strategy. Make a table that shows how the ordering strategies influence the time it takes to make a move?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_order: time=0.0090s, action=('drop', 0)\n",
      "center_first: time=0.0110s, action=('drop', 3)\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "# =========================\n",
    "# Task 3 — Move ordering đơn giản và so sánh thời gian\n",
    "# =========================\n",
    "# Giải thích: ta thử hai chiến lược đơn giản:\n",
    "#  - no ordering: dùng thứ tự actions() trả về\n",
    "#  - center-first: ưu tiên cột giữa (thường tốt cho Connect4)\n",
    "# So sánh thời gian chọn nước với và không có ordering.\n",
    "\n",
    "def order_center_first(board, acts, player):\n",
    "    # sắp xếp drop theo khoảng cách tới cột giữa (center columns trước)\n",
    "    cols = board.shape[1]\n",
    "    center = (cols - 1) / 2.0\n",
    "    def key(a):\n",
    "        if a[0] == \"drop\":\n",
    "            return abs(a[1] - center)\n",
    "        else:\n",
    "            # steal: đánh sau drop (có thể đặt trung bình)\n",
    "            return 10 + abs(a[2] - center)\n",
    "    return sorted(acts, key=key)\n",
    "\n",
    "# modified alphabeta that accepts move_order_fn\n",
    "def alphabeta_with_order(board, depth, alpha, beta, player, root_player, move_order_fn=None, heuristic_fn=None):\n",
    "    term = _is_terminal_value(board, root_player)\n",
    "    if term is not None:\n",
    "        return term, None\n",
    "    if depth == 0:\n",
    "        if heuristic_fn is not None:\n",
    "            return heuristic_fn(board, root_player, connect=CONNECT), None\n",
    "        return 0, None\n",
    "    best_action = None\n",
    "    value = -1e9\n",
    "    acts = actions(board, player)\n",
    "    if move_order_fn is not None:\n",
    "        acts = move_order_fn(board, acts, player)\n",
    "    for a in acts:\n",
    "        child = result(board, a, player)\n",
    "        v_child, _ = alphabeta_with_order(child, depth-1, -beta, -alpha, -player, root_player, move_order_fn, heuristic_fn)\n",
    "        v = -v_child\n",
    "        if v > value:\n",
    "            value = v; best_action = a\n",
    "        if value > alpha:\n",
    "            alpha = value\n",
    "        if alpha >= beta:\n",
    "            break\n",
    "    return value, best_action\n",
    "\n",
    "def minimax_agent_with_order(board, player=1, depth=MINIMAX_MAX_DEPTH, move_order_fn=None):\n",
    "    val, act = alphabeta_with_order(board, depth, -1e9, 1e9, player, player, move_order_fn, basic_heuristic)\n",
    "    return act\n",
    "\n",
    "# Đo thời gian so sánh\n",
    "board = empty_board((6,7))\n",
    "for name, order_fn in [(\"no_order\", None), (\"center_first\", order_center_first)]:\n",
    "    t0 = time.time()\n",
    "    act = minimax_agent_with_order(board.copy(), player=1, depth=3, move_order_fn=order_fn)\n",
    "    t1 = time.time()\n",
    "    print(f\"{name}: time={(t1-t0):.4f}s, action={act}\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first few moves\n",
    "\n",
    "Start with an empty board. This is the worst case scenario for minimax search with alpha-beta pruning since it needs solve all possible games that can be played (minus some pruning) before making the decision. What can you do? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty board -> opening move: ('drop', 3)\n",
      "After one move -> next: ('drop', 3)\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "# =========================\n",
    "# Task 3 — First few moves (chiến lược đơn giản)\n",
    "# =========================\n",
    "# Giải thích: với board rỗng, thay vì search sâu tốn thời gian, dùng quy tắc chọn cột giữa.\n",
    "# Nếu không rỗng, dùng minimax ở độ sâu giới hạn.\n",
    "\n",
    "def opening_then_minimax_agent(board, player=1, opening_choose_center=True, depth=3):\n",
    "    if opening_choose_center and (board == 0).all():\n",
    "        cols = board.shape[1]\n",
    "        mid = cols // 2\n",
    "        return (\"drop\", mid)\n",
    "    # khác: nếu số đĩa nhỏ (ví dụ <3), chọn center; else\tsearch\n",
    "    filled = np.sum(board != 0)\n",
    "    if filled < 2:\n",
    "        cols = board.shape[1]\n",
    "        return (\"drop\", cols // 2)\n",
    "    # else minimax\n",
    "    return minimax_agent_with_order(board, player=player, depth=depth, move_order_fn=order_center_first)\n",
    "\n",
    "# Thử vài nước mở đầu\n",
    "b = empty_board((6,7))\n",
    "print(\"Empty board -> opening move:\", opening_then_minimax_agent(b, 1))\n",
    "b2 = result(b, (\"drop\", 3), 1)\n",
    "print(\"After one move -> next:\", opening_then_minimax_agent(b2, -1))\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let the Minimax Search agent play a random agent on a small board. Analyze wins, losses and draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả (minimax vs random) trên 4x4 connect3, 50 games: {1: 41, -1: 9, 0: 0}\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "# =========================\n",
    "# Task 3 — Playtime: cho Minimax (cắt sâu) đấu Random trên board nhỏ\n",
    "# =========================\n",
    "# Giải thích: giảm kích thước board và depth để Minimax có thể chơi nhiều ván nhanh.\n",
    "def minimax_agent_small(board, player=1):\n",
    "    # agent chuyên cho board nhỏ: đặt max depth thấp\n",
    "    global MINIMAX_MAX_DEPTH\n",
    "    old = MINIMAX_MAX_DEPTH\n",
    "    MINIMAX_MAX_DEPTH = 4\n",
    "    act = minimax_agent_with_order(board, player=player, depth=4, move_order_fn=order_center_first)\n",
    "    MINIMAX_MAX_DEPTH = old\n",
    "    return act\n",
    "\n",
    "# play 100 games trên board 4x4 với connect=3 (nhanh)\n",
    "orig_connect = CONNECT\n",
    "CONNECT = 3\n",
    "def empty_board_4():\n",
    "    return empty_board((4,4))\n",
    "\n",
    "# băm lại các hàm dùng empty_board trong play -> nhỏ gọn thử nghiệm:\n",
    "def play_small(x_agent, o_agent, N=100):\n",
    "    results = {1:0, -1:0, 0:0}\n",
    "    for _ in range(N):\n",
    "        board = empty_board((4,4))\n",
    "        player = 1\n",
    "        while True:\n",
    "            agent = x_agent if player==1 else o_agent\n",
    "            action = agent(board.copy(), player)\n",
    "            if action is None:\n",
    "                results[0]+=1; break\n",
    "            if action not in actions(board, player):\n",
    "                # illegal -> opponent wins\n",
    "                results[-player]+=1; break\n",
    "            board = result(board, action, player)\n",
    "            is_term, winner = terminal(board, connect=3)\n",
    "            if is_term:\n",
    "                results[winner]+=1; break\n",
    "            player = -player\n",
    "    return results\n",
    "\n",
    "res = play_small(minimax_agent_small, random_player, N=50)\n",
    "print(\"Kết quả (minimax vs random) trên 4x4 connect3, 50 games:\", res)\n",
    "CONNECT = orig_connect\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Heuristic Alpha-Beta Tree Search [3 points] \n",
    "\n",
    "### Heuristic evaluation function\n",
    "\n",
    "Define and implement a heuristic evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "import numpy as np\n",
    "\n",
    "def advanced_heuristic(board, player, connect=CONNECT):\n",
    "    \"\"\"\n",
    "    Heuristic cải tiến:\n",
    "    - Duyệt mọi cửa sổ chiều dài `connect` (hàng, cột, hai đường chéo).\n",
    "    - Gán điểm theo số quân của player / opponent trong cửa sổ:\n",
    "      * win (connect của player) -> very large\n",
    "      * n of player's pieces and rest empty -> score increases (ex: 3->100, 2->10, 1->1)\n",
    "      * blocked cửa sổ (có cả 2 người) -> 0\n",
    "    - Thêm ưu tiên cho cột giữa.\n",
    "    Trả về giá trị số (lớn hơn có lợi cho `player`).\n",
    "    \"\"\"\n",
    "    rows, cols = board.shape\n",
    "    score = 0\n",
    "    center_col = cols // 2\n",
    "    # center control bonus\n",
    "    center_count = np.sum(board[:, center_col] == player)\n",
    "    score += center_count * 3\n",
    "\n",
    "    def score_window(window):\n",
    "        p_count = np.sum(window == player)\n",
    "        o_count = np.sum(window == -player)\n",
    "        empty_count = np.sum(window == 0)\n",
    "        if o_count > 0 and p_count > 0:\n",
    "            return 0\n",
    "        if p_count == connect:\n",
    "            return 100000\n",
    "        if o_count == connect:\n",
    "            return -100000\n",
    "        # heuristics for partial lines\n",
    "        if p_count == connect - 1 and empty_count == 1:\n",
    "            return 100\n",
    "        if p_count == connect - 2 and empty_count == 2:\n",
    "            return 10\n",
    "        if p_count == 1 and empty_count == connect - 1:\n",
    "            return 1\n",
    "        if o_count == connect - 1 and empty_count == 1:\n",
    "            return -80  # block urgent by opponent\n",
    "        if o_count == connect - 2 and empty_count == 2:\n",
    "            return -8\n",
    "        return 0\n",
    "\n",
    "    # scan directions\n",
    "    dirs = [(0,1),(1,0),(1,1),(1,-1)]\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            for dr, dc in dirs:\n",
    "                window = []\n",
    "                for k in range(connect):\n",
    "                    rr = r + k*dr\n",
    "                    cc = c + k*dc\n",
    "                    if 0 <= rr < rows and 0 <= cc < cols:\n",
    "                        window.append(board[rr, cc])\n",
    "                    else:\n",
    "                        window = None\n",
    "                        break\n",
    "                if window is not None:\n",
    "                    score += score_window(np.array(window))\n",
    "    return int(score)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutting off search \n",
    "\n",
    "Modify your Minimax Search with Alpha-Beta Pruning to cut off search at a specified depth and use the heuristic evaluation function. Experiment with different cutoff values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "# Cutoff search / agent sử dụng heuristic\n",
    "def make_heuristic_agent(depth=4, move_order_fn=order_center_first, name=None):\n",
    "    \"\"\"Trả về agent function dùng alphabeta_with_order với heuristic advanced_heuristic.\"\"\"\n",
    "    def agent(board, player=1):\n",
    "        val, act = alphabeta_with_order(board, depth, -1e9, 1e9, player, player, move_order_fn, advanced_heuristic)\n",
    "        return act\n",
    "    agent.__name__ = f\"heuristic_agent_d{depth}\" if name is None else name\n",
    "    return agent\n",
    "\n",
    "# Agent mẫu\n",
    "heur_agent_d3 = make_heuristic_agent(depth=3)\n",
    "heur_agent_d4 = make_heuristic_agent(depth=4)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with the same manually created boards as above to check if the agent spots winning opportunities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heuristic agent (depth=3) responses:\n",
      "Horizontal immediate win -> ('drop', 0)\n",
      "Vertical immediate win -> ('drop', 0)\n",
      "Diagonal immediate win -> ('drop', 3)\n",
      "Block opponent horizontal -> ('steal', 1, 4)\n",
      "Steal scenario -> ('steal', 0, 3)\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "# Experiment: kiểm tra cùng các board mẫu như Task 3 với agent heuristic\n",
    "tests = []\n",
    "# reuse boards from Task 3\n",
    "b1 = empty_board(); b1[5,0]=1; b1[5,1]=1; b1[5,2]=1\n",
    "tests.append((\"Horizontal immediate win\", b1, 1))\n",
    "b2 = empty_board(); b2[5,4]=1; b2[4,4]=1; b2[3,4]=1\n",
    "tests.append((\"Vertical immediate win\", b2, 1))\n",
    "b3 = empty_board(); b3[5,0]=1; b3[4,1]=1; b3[3,2]=1\n",
    "tests.append((\"Diagonal immediate win\", b3, 1))\n",
    "b4 = empty_board(); b4[5,0]=-1; b4[5,1]=-1; b4[5,2]=-1\n",
    "tests.append((\"Block opponent horizontal\", b4, 1))\n",
    "b5 = empty_board(); b5[5,0] = -1; b5[5,1] = 1; b5[4,1]=1; b5[3,1]=1\n",
    "tests.append((\"Steal scenario\", b5, 1))\n",
    "\n",
    "print(\"Heuristic agent (depth=3) responses:\")\n",
    "for name, board, player in tests:\n",
    "    act = heur_agent_d3(board.copy(), player)\n",
    "    print(name, \"->\", act)\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to make a move? Start with a smaller board with 4 columns and make the board larger by adding columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timing heuristic agent (average over 3 runs):\n",
      "Board 4x4, depth=2: avg time=0.0075s\n",
      "Board 4x4, depth=3: avg time=0.0315s\n",
      "Board 4x4, depth=4: avg time=0.0975s\n",
      "Board 5x5, depth=2: avg time=0.0104s\n",
      "Board 5x5, depth=3: avg time=0.1495s\n",
      "Board 5x5, depth=4: avg time=0.2222s\n",
      "Board 6x7, depth=2: avg time=0.0458s\n",
      "Board 6x7, depth=3: avg time=0.7609s\n",
      "Board 6x7, depth=4: avg time=0.8144s\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "# Timing: đo thời gian cho một nước đi với heuristic agent ở các kích thước và depth khác nhau\n",
    "import time\n",
    "\n",
    "def time_heur_agent(rows, cols, depth, repeats=3):\n",
    "    agent = make_heuristic_agent(depth=depth)\n",
    "    times = []\n",
    "    for _ in range(repeats):\n",
    "        b = empty_board((rows, cols))\n",
    "        t0 = time.time()\n",
    "        _ = agent(b, 1)\n",
    "        t1 = time.time()\n",
    "        times.append(t1 - t0)\n",
    "    return sum(times)/len(times)\n",
    "\n",
    "sizes = [(4,4),(5,5),(6,7)]\n",
    "depths = [2,3,4]\n",
    "print(\"Timing heuristic agent (average over 3 runs):\")\n",
    "for (r,c) in sizes:\n",
    "    for d in depths:\n",
    "        avg = time_heur_agent(r, c, d, repeats=3)\n",
    "        print(f\"Board {r}x{c}, depth={d}: avg time={avg:.4f}s\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playtime\n",
    "\n",
    "Let two heuristic search agents (different cutoff depth, different heuristic evaluation function) compete against each other on a reasonably sized board. Since there is no randomness, you only need to let them play once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kết quả (heur_d3 vs heur_d4) trên 6x7, 10 games: {1: 0, -1: 10, 0: 0}\n",
      "P1: 0 (0.00%), P-1: 10 (100.00%), Draw: 0 (0.00%)\n"
     ]
    }
   ],
   "source": [
    "# Your code/ answer goes here.\n",
    "# ...existing code...\n",
    "# Playtime: cho hai agent heuristic (khác depth) chơi 1 lần trên board chuẩn\n",
    "a1 = make_heuristic_agent(depth=3, name=\"heur_d3\")\n",
    "a2 = make_heuristic_agent(depth=4, name=\"heur_d4\")\n",
    "\n",
    "res = play(a1, a2, N=10, verbose=True)  # chơi 10 ván để có thống kê\n",
    "total = sum(res.values())\n",
    "print(\"Kết quả (heur_d3 vs heur_d4) trên 6x7, 10 games:\", res)\n",
    "print(f\"P1: {res[1]} ({res[1]/total:.2%}), P-1: {res[-1]} ({res[-1]/total:.2%}), Draw: {res[0]} ({res[0]/total:.2%})\")\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tournament task [+ 1 to 5 bonus point will be assigned separately]\n",
    "\n",
    "Find another student and let your best agent play against the other student's best player. You are allowed to use any improvements you like as long as you code it yourself. We will set up a class tournament on Canvas. This tournament will continue after the submission deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graduate student advanced task: Pure Monte Carlo Search and Best First Move [1 point]\n",
    "\n",
    "__Undergraduate students:__ This is a bonus task you can attempt if you like [+1 Bonus point].\n",
    "\n",
    "### Pure Monte Carlo Search\n",
    "\n",
    "Implement Pure Monte Carlo Search (see [tic-tac-toe-example](https://nbviewer.org/github/mhahsler/CS7320-AI/blob/master/Games/tictactoe_pure_monte_carlo_search.ipynb)) and investigate how this search performs on the test boards that you have used above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best First Move\n",
    "\n",
    "How would you determine what the best first move for a standard board ($6 \\times 7$) is? You can use Pure Monte Carlo Search or any algorithms that you have implemented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code/ answer goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
